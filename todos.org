* done
- [X] All titles should be written out as a file.
- [X] References should only be linked if it is available.
- [X] More dynamic search bar (which already requires JS)
  - We can avoid including titles.json in every file by just copying it to the output. We then have to do a request for it every time though. This is another case for rendering on first request.
- [X] A 404 page
- [X] Consider using Eleventy Serverless because we're on track to a million files in one folder at this rate. Although, who knows, maybe that's actually fine: https://stackoverflow.com/questions/197162/ntfs-performance-and-large-volumes-of-files-and-directories
  See [[file:internal-docs.org::df677ea0-0d20-4f07-bed2-df3d56fe4d45][Internal Docs: Rendering pages at first request instead of at build time]].
- [X] Fix stray <li>s for words without a type
- [X] Add links to search word in Moedict, Wiktionary, etc.
- [X] Copyright information for each dictionary like Weblio's footer
- [X] Dictionary header should link to the original dictionary, preferably to the same term
- [X] Make the search bar appear as if it's another window
* todos
- [ ] Figure out how to decode the ={[xxxx]}= thing
- [ ] (This might blow up file count even more) pronunciation search: collect all pronunciations, then list all words with a given pronunciation for all pronunciations
- [ ] Potentially incorporate https://github.com/ChhoeTaigi/ChhoeTaigiDatabase
* Updating data

moedict-data and moedict-data-hakka are out of date. So is moedict-process. (moedict-data-twblg isn't.)

We can:

- Update moedict-process and such so that Moedict itself is updated
- Just process the files from Ministry of Education directly

I kind of prefer the latter because Moedict splits the definition up too much, in my opinion.

You can convert the .xlsx into CSV then use [[https://www.npmjs.com/package/csv-parse][csv-parse]] to parse it, then process each item accordingly.
